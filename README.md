Working with Climate Data
================
Nassos Stylianou & Becky Dale
21/02/2022

NOTE - CHANGE THIS TO BE A LITTLE MORE GENERAL ABOUT GRIDDED DATA,
RATHER THAN JUST NETCDF ONLY

## What are netCDF files?

NetCDF is a widely used format for exchanging or distributing climate
data. These types of files were originally developed for storing and
distributing climate data, such as those generated by climate simulation
or reanalysis models, but the format and protocols can and have been
used for other ‘gridded’ data sets or where multidimensional arrays of
data are generated.

NetCDF files contain metadata that describes what is contained in a
file, such as the latitude and longitude layout of the grid, the names
and units of variables in the data set, and “attributes” that describe
things like missing value codes, or offsets and scale factors that may
have been used to compress the data.

The first thing to get your head round before diving in is the structure
of a netcdf file. They are multi-dimensional arrays, which often hold
data in numerous ‘bands’, these tend to be related to time, for example
there could be one band for each month or year, and each band tends to
have three dimensions, which tend to be latitude, longitude and the
value (temperature, rainfall, number of days over X degrees or whatever
else).

## How can you work with netcdf data?

There are a number of different ways, software and packages to work with
netCDF files. A lot of analysis and data wrangling with these files is
done with Python, however they can be read into R and there are a few
packages for working with them. You can also load them up into QGIS -
they are pretty much raster files really. Software like Panoply,
developed by NASA, is also a great to get an initial feel of the data.
Each option has different advantages and disadvantages. In the sections
below I will go through how to work with each one and at the bottom of
each one will include a user case where this option makes sense, in my
experience so far (there could be many other use cases I haven’t got
to).

## Viewing your data in Panoply

PANOPLY SCREENSHOTS AND NOTES

## Working with your data in R

INTRO

### Load the packages you need

``` r
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(RNetCDF) # package for working with netcdfs
library(rgdal) # package for geospatial analysis
library(chron) #package to help with time conversions
library(dplyr) #package for data manipulation in R
library(lubridate) #package  for working with dates in R
```

### Reading a gridded file into R (nc\_open from ncd4)

You can open a netcdf file using the `nc_open()` function from the
`ncdf4` library.

At its simplest, all you need is the filepath of your netcdf file, and
the data from the file into a new variable you can access in R.

The file we are using is inside our `data` folder. So all you need to do
to load it in is run the following code:

``` r
# This loads the data in and saves it to a variable called nc_data
nc_data <- nc_open('~/Dropbox (BBC)/Visual Journalism/Data/2022/working_with_climate_data_nicar22/data/cru_ts4.05.2011.2020.tmp.dat.nc')

# To see some basic information about the data, print out the file. 
print(nc_data)
```

    ## File ~/Dropbox (BBC)/Visual Journalism/Data/2022/working_with_climate_data_nicar22/data/cru_ts4.05.2011.2020.tmp.dat.nc (NC_FORMAT_CLASSIC):
    ## 
    ##      2 variables (excluding dimension variables):
    ##         float tmp[lon,lat,time]   
    ##             long_name: near-surface temperature
    ##             units: degrees Celsius
    ##             correlation_decay_distance: 1200
    ##             _FillValue: 9.96920996838687e+36
    ##             missing_value: 9.96920996838687e+36
    ##         int stn[lon,lat,time]   
    ##             description: number of stations contributing to each datum
    ##             _FillValue: -999
    ##             missing_value: -999
    ## 
    ##      3 dimensions:
    ##         lon  Size:720
    ##             long_name: longitude
    ##             units: degrees_east
    ##         lat  Size:360
    ##             long_name: latitude
    ##             units: degrees_north
    ##         time  Size:120   *** is unlimited ***
    ##             long_name: time
    ##             units: days since 1900-1-1
    ##             calendar: gregorian
    ## 
    ##     8 global attributes:
    ##         Conventions: CF-1.4
    ##         title: CRU TS4.05 Mean Temperature
    ##         institution: Data held at British Atmospheric Data Centre, RAL, UK.
    ##         source: Run ID = 2103051243. Data generated from:tmp.2103041709.dtb
    ##         history: Fri  5 Mar 13:25:53 GMT 2021 : User harry : Program makegridsauto.for called by update.for
    ##         references: Information on the data is available at http://badc.nerc.ac.uk/data/cru/
    ##         comment: Access to these data is available to any registered CEDA user.
    ##         contact: support@ceda.ac.uk

When you print the file, you will see some basic information about the
file, which resembles the metadata of the file. It does not print the
data in the file as a standard dataframe would for example. You can also
see that the file is essentially a list.

So the informaiton below is key to how we can go about re-shaping the
data from its list/raster format to a more ‘rectangular’, dataframe-like
format, as we will construct the dataframe from the dimensions below.

### Extracting variables

As you can see from the metadata, there are the dimensions longitude
(lon), latitude (lat), time, which we want to examine first.

To extract a variable from the netcdf file, we can use the `ncvar_get()`
function from the `ncdf4` package. The first argument you should pass to
the function is the name of your netcdf file in R and the second
argument is the name of the variable (dimension in this case) we want to
extract. The `ncvar_get()` function actually extracts the data as
arrays, so we will need to do some formatting to them later on to change
the data type.

We know that the longitude is stored in the variable/dimension called
“lon” as we can see that in the metadata above, under the dimensions. We
can also find the names of the different dimensions and variables in R,
if we run `View(nc_data)`. Running the `View()` function should open up
a new tab in R, which shows us all the different list elements of the
netcdf file. You can click on the `dim` and `var` lists to see the names
of the dimensions and variables.

#### Longitude

Let’s start with the longitude.

``` r
# The line of code below extracts the longitude variable from the netcdf file as an array into the lon variable.
lon <- ncvar_get(nc_data,"lon")

# Using the dim() function and passing our new lon variable to it gives us the dimensions of the l and saves it to the nlon variable.
nlon <- dim(lon)

# These functions just give you some insight into the lon variable
head(lon)
```

    ## [1] -179.75 -179.25 -178.75 -178.25 -177.75 -177.25

``` r
tail(lon)
```

    ## [1] 177.25 177.75 178.25 178.75 179.25 179.75

``` r
max(lon)
```

    ## [1] 179.75

``` r
min(lon)
```

    ## [1] -179.75

#### Latitude

We then need to do the same with the latitude, to have both the
longitude and latitude in different variables.

``` r
# The line of code below extracts the latitude variable from the netcdf file as an array into the lat variable.
lat <- ncvar_get(nc_data,"lat")
# Using the dim() function and passing our new lat variable to it gives us the dimensions of the lat and saves it to the nlat variable.
nlat <- dim(lat)
# These functions just give you some insight into the lat variable
head(lat)
```

    ## [1] -89.75 -89.25 -88.75 -88.25 -87.75 -87.25

``` r
tail(lat)
```

    ## [1] 87.25 87.75 88.25 88.75 89.25 89.75

``` r
max(lat)
```

    ## [1] 89.75

``` r
min(lat)
```

    ## [1] -89.75

Running the different `head`, `tail`, `max` and `min` functions will
show you the first few and last few latitude and longitude values for
your data, which are in essence the centre points of your grid in the
raster dataset.

You can also see that `the ncvar_get()` function actually extracts the
data as 1D arrays.

#### Time

The next step is to extract the time variable from your dataset - this
is a little trickier because the time variable will need to be
interpreted based on the time units, it is rarely a straightforward
‘date’.

To find out what time unit you are dealing with for the specific dataset
in question, a lot of the time this should be in the metadata
information that you get when you `print()` the netcdf dataset after you
have loaded it in. So if you scroll back up to look at the information
printed out for this dataset, you can see the `units` for the `time`
dimension are:

``` r
time <- ncvar_get(nc_data,"time")

time
```

    ##   [1] 40557 40587 40616 40647 40677 40708 40738 40769 40800 40830 40861 40891
    ##  [13] 40922 40952 40982 41013 41043 41074 41104 41135 41166 41196 41227 41257
    ##  [25] 41288 41318 41347 41378 41408 41439 41469 41500 41531 41561 41592 41622
    ##  [37] 41653 41683 41712 41743 41773 41804 41834 41865 41896 41926 41957 41987
    ##  [49] 42018 42048 42077 42108 42138 42169 42199 42230 42261 42291 42322 42352
    ##  [61] 42383 42413 42443 42474 42504 42535 42565 42596 42627 42657 42688 42718
    ##  [73] 42749 42779 42808 42839 42869 42900 42930 42961 42992 43022 43053 43083
    ##  [85] 43114 43144 43173 43204 43234 43265 43295 43326 43357 43387 43418 43448
    ##  [97] 43479 43509 43538 43569 43599 43630 43660 43691 43722 43752 43783 43813
    ## [109] 43844 43874 43904 43935 43965 43996 44026 44057 44088 44118 44149 44179

So by printing out the time variable after you have extracted it from
the netcdf file, each time unit is a number rather than a date and as we
know from the information we have, that number is `days since 1900-1-1`.

This will need to be factored in to convert the formats a little later
on.

To actually turn the units from the time dimension into a variable, we
use the ncatt\_get() function to extract the units attribute

``` r
tunits <- ncatt_get(nc_data,"time","units")

# And just like the lat and lon, we can get the time variable dimensions as well using the dim() function.
ntime <- dim(time)
```

#### Data variable - temperature

We can extract the data from the array in a very similar way. We know
the data variable we are after (temperature) is called `tmp`, so we can
use the same `ncvar_get()` function:

``` r
tmp_array <- ncvar_get(nc_data, "tmp")
```

So if we look at all our global environment variables now, we have the
longitude, latitude, time, and temperature arrays. You can now get an
understanding of the dimensions of each of them and how they will fit in
together. The temperature array is a 3D array and matches the dimensions
of the lon, lat and time ones, which are 1D arrays.

So essentially, the dimensions of the array are 720 lons, 360 lats and
120 times (10 years, 12 months for each year.

You can verify this by running dim(tmp\_array) and the dims of each
variable.

The other really useful thing to find out about your temperature data
variable at this stage is what potential fill value was used for missing
data. This is a common feature of some netcdf files which may be
different to standard dataframes in R. You can find the fill value by
running the `ncatt_get()` function as below - the name of your data as
the first argument, the name of your variable as the second argument and
"\_FillValue" as the third argument

``` r
# Finds the fill value used for missing data for the precipitation variable
fillvalue <- ncatt_get(nc_data, "tmp", "_FillValue")
fillvalue
```

    ## $hasatt
    ## [1] TRUE
    ## 
    ## $value
    ## [1] 9.96921e+36

The fill value in this particular case is
`9969209968386869046778552952102584320`.

The best thing to do is probably first, might just be for housekeeping,
replace any fill values with ’NA’s, as would be standard practice in R.
Here’s how:

``` r
# Finds the fill value used for missing data for the temperature variable
tmp_array[tmp_array == fillvalue$value] <- NA
```

### Reshaping your data

Netcdf files and the data within them are naturally raster ‘slabs’ (a
longitude by latitude “slice”), bricks (a longitude by latitude by
time), or 4-d arrays (e.g. a longitude by latitude by height by time),
while most data analysis routines in R expect 2-d
variable-by-observation data frames.

In addition, as we have seen with the time variable already, time is
usually stored in the “time since” format that not a proper date format

### Converting the time variable

So before reshaping the data format to a 2D dataframe format we can work
with, we will need to convert the time variable.

The time variable in “time-since” units can be converted into actual
time values by splitting the time tunits$value string into its component
parts, and then using the chron() function to determine the absolute
value of each time value from the time origin.

``` r
# example of how we can convert time -- split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])

time_cols <- chron(time, origin=c(tmonth, tday, tyear)) %>%
  lubridate::mdy() %>%
  as.character()
```

So if you look at the time values in days since, this is what you get:

``` r
print(time)
```

    ##   [1] 40557 40587 40616 40647 40677 40708 40738 40769 40800 40830 40861 40891
    ##  [13] 40922 40952 40982 41013 41043 41074 41104 41135 41166 41196 41227 41257
    ##  [25] 41288 41318 41347 41378 41408 41439 41469 41500 41531 41561 41592 41622
    ##  [37] 41653 41683 41712 41743 41773 41804 41834 41865 41896 41926 41957 41987
    ##  [49] 42018 42048 42077 42108 42138 42169 42199 42230 42261 42291 42322 42352
    ##  [61] 42383 42413 42443 42474 42504 42535 42565 42596 42627 42657 42688 42718
    ##  [73] 42749 42779 42808 42839 42869 42900 42930 42961 42992 43022 43053 43083
    ##  [85] 43114 43144 43173 43204 43234 43265 43295 43326 43357 43387 43418 43448
    ##  [97] 43479 43509 43538 43569 43599 43630 43660 43691 43722 43752 43783 43813
    ## [109] 43844 43874 43904 43935 43965 43996 44026 44057 44088 44118 44149 44179

If we print out the converted time, this is what we get:

``` r
print(time_cols)
```

    ##   [1] "2011-01-16" "2011-02-15" "2011-03-16" "2011-04-16" "2011-05-16"
    ##   [6] "2011-06-16" "2011-07-16" "2011-08-16" "2011-09-16" "2011-10-16"
    ##  [11] "2011-11-16" "2011-12-16" "2012-01-16" "2012-02-15" "2012-03-16"
    ##  [16] "2012-04-16" "2012-05-16" "2012-06-16" "2012-07-16" "2012-08-16"
    ##  [21] "2012-09-16" "2012-10-16" "2012-11-16" "2012-12-16" "2013-01-16"
    ##  [26] "2013-02-15" "2013-03-16" "2013-04-16" "2013-05-16" "2013-06-16"
    ##  [31] "2013-07-16" "2013-08-16" "2013-09-16" "2013-10-16" "2013-11-16"
    ##  [36] "2013-12-16" "2014-01-16" "2014-02-15" "2014-03-16" "2014-04-16"
    ##  [41] "2014-05-16" "2014-06-16" "2014-07-16" "2014-08-16" "2014-09-16"
    ##  [46] "2014-10-16" "2014-11-16" "2014-12-16" "2015-01-16" "2015-02-15"
    ##  [51] "2015-03-16" "2015-04-16" "2015-05-16" "2015-06-16" "2015-07-16"
    ##  [56] "2015-08-16" "2015-09-16" "2015-10-16" "2015-11-16" "2015-12-16"
    ##  [61] "2016-01-16" "2016-02-15" "2016-03-16" "2016-04-16" "2016-05-16"
    ##  [66] "2016-06-16" "2016-07-16" "2016-08-16" "2016-09-16" "2016-10-16"
    ##  [71] "2016-11-16" "2016-12-16" "2017-01-16" "2017-02-15" "2017-03-16"
    ##  [76] "2017-04-16" "2017-05-16" "2017-06-16" "2017-07-16" "2017-08-16"
    ##  [81] "2017-09-16" "2017-10-16" "2017-11-16" "2017-12-16" "2018-01-16"
    ##  [86] "2018-02-15" "2018-03-16" "2018-04-16" "2018-05-16" "2018-06-16"
    ##  [91] "2018-07-16" "2018-08-16" "2018-09-16" "2018-10-16" "2018-11-16"
    ##  [96] "2018-12-16" "2019-01-16" "2019-02-15" "2019-03-16" "2019-04-16"
    ## [101] "2019-05-16" "2019-06-16" "2019-07-16" "2019-08-16" "2019-09-16"
    ## [106] "2019-10-16" "2019-11-16" "2019-12-16" "2020-01-16" "2020-02-15"
    ## [111] "2020-03-16" "2020-04-16" "2020-05-16" "2020-06-16" "2020-07-16"
    ## [116] "2020-08-16" "2020-09-16" "2020-10-16" "2020-11-16" "2020-12-16"

So you can see that the time-stampsfor the particular set of data is The
“time-stamp” for this particular data set is the mid-point of the
interval for each month of the year for 2011 to 2020. There are other
ways in which the “time” associated with a long-term mean is represented
in climate stats, but essentially the code above shows us how to change
the date format from days since to an actual date - whatever that date
ends up representing.

A note on time and formatting - bear in mind there are a number of
different ways that time data will be represented and you can turn it
into more meaningful date formats in different ways once you understand
that date pattern. You do not always have to change the dates in the way
it was done above by unlisting and stringspliting, so always be ready to
adapt.

### Turning the data into a dataframe

The first step in the process is to convert the array into a vector -
the code and process below will only work only if the netCDF file - and
by default the data array - follows the “CF” conventions, i.e. that the
variable has been defined to have dimensions nlon by nlat by nt, in that
order. We have seen from interrogating our data above, that this is the
case for our data - and most netcdf data you will encounter should
follow the same format.

So if you remember from earlier, we had turned our data into a really
large ‘temperature’ array by identifying the variable where the
precipitation data was held and using the ncvar\_get() function.

This is what we had done: `tmp_array <- ncvar_get(nc_data,"tmp")`

So once we have our array, what we then need to do is turn it into a
vector

``` r
tmp_vector_long <- as.vector(tmp_array)
```

To check just how long this vector is, run length(tmp\_vector\_long) -
and you can see that the length is 31104000

So we know that our data is made up of latitude, longitude, time and
temperature variables. We know that we have 120 time values (12 monthls
over 10 year) and the number of rows will be the number of longitude
values by the number of latitude values, as these are grids.

So we then reshape the vector into a matrix based on this logic and
using the nlon, nlat and ntime values we created earlier when evaluating
our netcdf dataset.

``` r
# reshape the vector into a matrix
tmp_matrix <- matrix(tmp_vector_long, nrow=nlon*nlat, ncol=ntime)

dim(tmp_matrix)
```

    ## [1] 259200    120

So in total this should give us a matrix sized 259200 (720 lons x 360
lats) by 120 (time), which adds up to 31104000 from earlier Bear in mind
that we are not just multiplying these two values (720 by 360) to get
our number of rows when creating the matrix, as the number of rows will
depend on the number of latitude and longitude sized grids, so we use
the variables nlon and nlat we created that are specific to the
dimensions of this specific dataset.

Then reshape that vector into a 259200 by 120 matrix using the matrix()
function, and verify its dimensions, which should be 259200 by 120.

S0 lets see what our matrix actually looks like - lets chekc it without
the NAs, as a lot of the NAs would be for values in the sea, of which
there are many.

``` r
head(na.omit(tmp_matrix))
```

    ##      [,1]     [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]    [,12]
    ## [1,]  7.7 9.000000  7.6  4.5  4.7  2.3  1.5  1.5  2.7   5.5   6.5 8.800000
    ## [2,]  7.8 9.000000  7.6  4.3  4.5  2.1  1.2  1.3  2.5   5.5   6.6 8.900001
    ## [3,]  7.8 8.900001  7.3  4.1  4.2  1.7  0.9  1.4  2.2   5.4   6.5 8.800000
    ## [4,]  7.1 8.300000  7.1  4.3  4.4  2.2  1.5  1.1  2.3   4.6   5.7 8.200000
    ## [5,]  7.3 8.500000  7.3  4.5  4.5  2.3  1.7  1.2  2.6   4.9   6.0 8.500000
    ## [6,]  7.2 8.200000  7.0  4.1  4.1  1.9  1.4  0.9  2.4   5.0   6.0 8.400001
    ##      [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]
    ## [1,]   9.1   6.5   7.9   4.4   3.8   1.5   2.5   3.9   3.9   4.6   6.1   5.8
    ## [2,]   9.2   6.5   7.9   4.3   3.6   1.3   2.4   3.7   3.7   4.6   6.2   5.9
    ## [3,]   9.2   6.4   7.6   4.1   3.4   0.9   2.2   3.8   3.4   4.4   6.0   5.8
    ## [4,]   8.6   5.5   7.5   4.3   3.1   1.1   1.8   3.5   3.6   3.9   5.6   5.0
    ## [5,]   8.8   5.8   7.7   4.4   3.3   1.3   2.0   3.7   3.8   4.2   5.9   5.3
    ## [6,]   8.7   5.5   7.4   4.1   2.9   0.9   1.7   3.4   3.6   4.3   5.9   5.2
    ##         [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36]
    ## [1,] 9.100000   8.1   7.7   7.8   4.2   3.9   3.2   1.3   3.1   5.1   5.2   6.1
    ## [2,] 9.100000   8.1   7.7   7.8   4.0   3.7   2.9   1.1   3.0   5.1   5.3   6.2
    ## [3,] 9.100000   8.0   7.4   7.6   3.7   3.3   2.7   1.2   2.7   5.0   5.2   6.1
    ## [4,] 8.900001   7.4   7.1   7.1   4.0   3.5   3.0   1.0   2.3   4.5   4.4   5.5
    ## [5,] 9.000000   7.6   7.3   7.3   4.1   3.7   3.2   1.1   2.6   4.8   4.8   5.8
    ## [6,] 8.900001   7.3   7.0   7.0   3.7   3.3   2.8   0.8   2.4   4.9   4.8   5.7
    ##      [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48]
    ## [1,]   6.5   7.6   6.1   5.8   4.5   3.1   3.3   3.2   3.5   4.9   5.3   6.9
    ## [2,]   6.7   7.6   6.1   5.8   4.3   2.9   3.2   2.9   3.4   4.9   5.4   7.0
    ## [3,]   6.7   7.5   5.8   5.6   4.0   2.5   3.0   3.0   3.1   4.8   5.3   6.9
    ## [4,]   5.8   7.2   5.6   5.1   4.1   2.5   2.2   2.8   2.8   4.1   4.7   6.2
    ## [5,]   6.0   7.4   5.8   5.3   4.2   2.7   2.5   3.0   3.1   4.4   5.0   6.5
    ## [6,]   5.9   7.0   5.6   5.0   3.8   2.3   2.2   2.7   2.9   4.6   5.0   6.4
    ##      [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60]
    ## [1,]   7.7   8.1   8.0   6.1   4.6   2.3   1.6   2.4   1.8   4.8   5.8   6.5
    ## [2,]   7.8   8.1   8.0   6.1   4.4   2.0   1.4   2.2   1.7   4.8   5.9   6.7
    ## [3,]   7.8   8.0   7.7   5.9   4.1   1.6   1.2   2.3   1.4   4.7   5.8   6.6
    ## [4,]   7.1   7.5   7.6   5.3   4.1   2.3   1.4   1.9   1.5   3.8   5.2   5.7
    ## [5,]   7.3   7.7   7.8   5.5   4.2   2.5   1.6   2.1   1.8   4.1   5.5   6.0
    ## [6,]   7.2   7.4   7.5   5.2   3.9   2.1   1.3   1.8   1.6   4.2   5.5   5.9
    ##      [,61] [,62]    [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72]
    ## [1,]   8.1   8.0 8.400001   4.4   4.1   5.3   3.5   2.4   5.4   6.3   6.6   7.3
    ## [2,]   8.2   8.0 8.400001   4.3   4.0   5.1   3.3   2.2   5.4   6.3   6.7   7.4
    ## [3,]   8.2   7.9 8.100000   4.1   3.7   4.7   3.1   2.3   5.1   6.2   6.6   7.3
    ## [4,]   7.7   7.4 8.000000   3.8   3.4   4.5   2.8   2.1   4.2   5.3   6.0   6.5
    ## [5,]   7.9   7.6 8.200000   4.0   3.5   4.8   3.0   2.3   4.6   5.6   6.3   6.8
    ## [6,]   7.8   7.3 7.900000   3.7   3.1   4.4   2.7   2.0   4.4   5.7   6.3   6.8
    ##      [,73]    [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84]
    ## [1,]   7.9 8.800000   7.5   5.8   4.9   2.0   4.3   3.5   4.0   4.7   6.0   7.1
    ## [2,]   8.0 8.800000   7.5   5.7   4.7   1.9   4.1   3.3   3.9   4.7   6.1   7.2
    ## [3,]   8.0 8.700000   7.2   5.5   4.4   1.5   3.9   3.4   3.6   4.6   6.0   7.1
    ## [4,]   7.2 8.200000   6.8   5.2   4.4   1.4   3.9   3.1   3.4   4.0   5.2   6.3
    ## [5,]   7.4 8.400001   7.0   5.4   4.5   1.7   4.1   3.3   3.7   4.3   5.5   6.6
    ## [6,]   7.4 8.100000   6.7   5.1   4.1   1.3   3.8   3.0   3.5   4.4   5.5   6.5
    ##         [,85]    [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95]
    ## [1,] 8.700000 9.400001   7.0   5.6   4.5   2.7   2.6   3.7   3.4   4.6   6.5
    ## [2,] 8.800000 9.400001   7.1   5.5   4.3   2.5   2.4   3.5   3.3   4.6   6.7
    ## [3,] 8.700000 9.300000   6.8   5.4   4.0   2.1   2.3   3.6   3.1   4.5   6.6
    ## [4,] 8.200000 8.800000   6.4   4.7   3.9   1.9   1.5   3.1   2.4   3.5   5.8
    ## [5,] 8.400001 9.000000   6.6   5.0   4.0   2.1   1.7   3.3   2.7   3.8   6.1
    ## [6,] 8.300000 8.700000   6.3   4.7   3.6   1.8   1.5   3.0   2.6   3.9   6.1
    ##      [,96] [,97] [,98] [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106]
    ## [1,]   8.2   7.4   7.7   7.7    5.9    4.3    3.2    3.4    2.6    3.3    4.8
    ## [2,]   8.3   7.6   7.7   7.7    5.8    4.1    3.0    3.2    2.4    3.2    4.8
    ## [3,]   8.2   7.6   7.6   7.4    5.7    3.8    2.6    3.0    2.5    3.0    4.7
    ## [4,]   7.6   6.8   7.2   7.2    5.2    4.0    2.5    2.8    1.9    2.5    4.1
    ## [5,]   8.0   7.0   7.4   7.4    5.5    4.1    2.7    3.0    2.1    2.8    4.4
    ## [6,]   7.8   6.9   7.1   7.1    5.2    3.7    2.3    2.7    1.8    2.6    4.5
    ##      [,107] [,108]   [,109]   [,110]   [,111] [,112] [,113] [,114] [,115]
    ## [1,]    6.1    7.9 8.400001 9.200000 8.400001    6.8    5.1    3.0    1.2
    ## [2,]    6.2    8.0 8.500000 9.200000 8.400001    6.8    5.0    2.9    1.1
    ## [3,]    6.1    7.9 8.600000 9.100000 8.000000    6.6    4.7    2.5    0.9
    ## [4,]    5.1    7.3 7.600000 8.500000 8.000000    6.3    4.7    2.2   -0.1
    ## [5,]    5.4    7.6 7.900000 8.700000 8.200000    6.5    4.8    2.4    0.2
    ## [6,]    5.5    7.5 7.800000 8.400001 7.900000    6.2    4.4    2.1    0.0
    ##      [,116] [,117] [,118] [,119] [,120]
    ## [1,]    1.7    3.5    5.1    7.5    7.8
    ## [2,]    1.4    3.3    5.1    7.6    7.9
    ## [3,]    1.5    3.0    5.0    7.5    7.8
    ## [4,]    1.5    3.0    4.5    6.9    7.0
    ## [5,]    1.7    3.3    4.8    7.1    7.3
    ## [6,]    1.4    3.1    4.9    7.1    7.2

So this matrix is basically the temperature data only, so we now need to
add the latitude and longitude values to this, which we can do by
creating a second dataframe and binding the two together.

``` r
# creating lon lat matrix
lonlat_matrix <- as.matrix(expand.grid(lon,lat))

# bind the two matrices together and turn into a dataframe
tmp_dataframe <- data.frame(cbind(lonlat_matrix, tmp_matrix))
```

Essentially, as you can see the dataset starts in the far corners of the
world in a WGS84 system, hence the NAs as there are no values for the
ocean in our dataset.

The other thing that you can see is that there are no column names - so
we can set these ourselves. We know the first two columns are the
longitude and latitude, as when we joined up the lonlat matric with the
tmp matrix, we put the lonlat matrix first. Then, the column names for
each of the tmp columns are the time columns. This is where our time
conversion comes into use, as we can use that to set our column names.

``` r
lon_lat_cols <- c("lon", "lat")

tmp_cols <- c(lon_lat_cols, 
              time_cols)

colnames(tmp_dataframe) <- tmp_cols
```

NEXT STEPS

PLOT?

### Using the raster package to load in data and do analysis (anomaly analysis in fewer steps)
